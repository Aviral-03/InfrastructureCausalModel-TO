---
title: "dump"
format: html
editor: visual
---

## Park and Recreation Facility Projects {#sec-parks}

The Park and Recreation Facility Projects dataset [@toronto_parks], published by the Parks, Forestry and Recreation Division and last updated on July 22, 2024, contains information about park and recreation facility projects in Toronto. This dataset includes details about the project name, location, ward number, and project status. Park and recreation facilities are essential public amenities that contribute to the quality of life and well-being of residents, providing spaces for recreation, leisure, and community engagement.

We choose this dataset to evaluate the how budget allocations are related to the number of park and recreation facility projects in each ward. The number of park projects can serve as a proxy for community development and public service enhancement, reflecting the need for investments in public amenities and infrastructure. By analyzing the relationship between park projects and budget allocations, we can gain insights into how public service enhancements influence the distribution of resources across the city. This will also help us understand how the city's budget decisions align with community development trends and public service needs in different wards, and determine if there are any disparities in resource allocation based on public service enhancements to certain wards.

```{r}
parks_data <- here::here("data/01-raw_data/Park and Recreation Facility Projects - 4326.csv")
parks <- read_csv(parks_data)

# create a graph of the number of parks by ward_number
parks |>
  count(ward_number) |>
  ggplot(aes(x = ward_number, y = n)) +
  geom_col() +
  labs(x = "Ward number", y = "Number of parks") +
  theme_minimal()
```

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(palmerpenguins)
```

# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data [@shelter].... Following @tellingstories, we consider...

Overview text

## Measurement

Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Add graphs, tables and text. Use sub-sub-headings for each outcome variable or update the subheading to be singular.

Some of our data is of penguins (@fig-bills), from @palmerpenguins.

```{r}
#| label: fig-bills
#| fig-cap: Bills of penguins
#| echo: false

ggplot(penguins, aes(x = island, fill = species)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange","purple","cyan4"),
                    guide = "none") +
  theme_minimal() +
  facet_wrap(~species, ncol = 1) +
  coord_flip()
```

Talk more about it.

And also planes (@fig-planes). (You can change the height and width, but don't worry about doing that until you have finished every other aspect of the paper - Quarto will try to make it look nice and the defaults usually work well once you have enough text.)

```{r}
#| label: fig-planes
#| fig-cap: Relationship between wing length and width
#| echo: false
#| warning: false
#| message: false

analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

analysis_data |> 
  ggplot(aes(x = width, y = length)) +
  geom_point(alpha = 0.8) +
  theme_minimal() +
  labs(x = "Wing width (mm)",
       y = "Wing length (mm)")
```

Talk way more about it.

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.

# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.

# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```

# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this.

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {.unnumbered}

# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows...

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheckandposteriorvsprior
#| layout-ncol: 2
#| fig-cap: "Examining how the model fits, and is affected by, the data"
#| fig-subcap: ["Posterior prediction check", "Comparing the posterior with the prior"]

pp_check(first_model) +
  theme_classic() +
  theme(legend.position = "bottom")

posterior_vs_prior(first_model) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "bottom") +
  coord_flip()
```

## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...

```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(first_model, "trace")

plot(first_model, "rhat")
```

```{r}
install.packages("tinytable")
```

```{r}
#| include: false
#| warning: false
#| message: false

library(boot)
library(janitor)
library(modelsummary)
library(rstanarm)
library(tidyverse)
library(collapse)
library(tinytable)
library(marginaleffects)
```

```{r}
# combine all the years data for each ward and for each category
model_data <- analysis_budget_data |>
  group_by(ward_id, category, ward) |>
  summarize(total_10_year = sum(total_10_year)) |>
  pivot_wider(names_from = category, values_from = total_10_year)

# combine the model data with the ward profile data
model_data <- model_data |>
  left_join(analysis_ward_data, by = "ward_id") |>
  select(ward_id, ward.x, population, average_household_income, `Growth Related`, `State of Good Repair`, `Service Improvement and Enhancement`) |>
  rename(ward = ward.x) |>
  left_join(analysis_building_permits, by = "ward_id") |>
  rename(growth_related = `Growth Related`, state_of_good_repair = `State of Good Repair`, service_improvement = `Service Improvement and Enhancement`)

```

```{r}
# Install and load rstanarm if not installed
# install.packages("rstanarm")
# Load required libraries
library(rstanarm)
library(bayesplot)

# Prepare the data (assuming you've read the CSV)
data <- read.csv(here::here("data/02-analysis_data/model_data.csv"))

write.csv(data, here::here("data/02-analysis_data/model_data.csv"))

# Basic Poisson Model
permits_model <- stan_glm(
  building_permits ~ ward_id,
  data = model_data,
  family = poisson(link = "log"),s
  prior = normal(0, 2.5),  # Weakly informative prior
  prior_intercept = normal(0, 10),
  chains = 4,
  iter = 2000,
  seed = 123
)

# Model summary
summary(permits_model)

# Diagnostic plots
plot(permits_model)

# Posterior predictive checks
pp_check(permits_model)

# Credible intervals
posterior_interval(permits_model)

# Visualize posterior distributions
mcmc_areas(permits_model)

# Predictive performance
# Compare observed vs. predicted
predicted_permits <- posterior_predict(permits_model)

```

```{r}
library(rstanarm)
library(bayesplot)

# Fit the Negative Binomial model
# building_permits is the target variable
# population, average_household_income, growth_related, state_of_good_repair, and service_improvement are predictors
model <- stan_glmer(
  growth_related ~ population + average_household_income + (1 | ward_id),
  data = data,
  family = neg_binomial_2(link = "log"),
  chains = 4,
  iter = 2000,
  seed = 1234
)

# Summarize the model
summary(model)

# Posterior predictive checks
pp_check(model)

# Diagnostic plots
plot(model)

# Posterior predictive checks
pp_check(model)

# Credible intervals
posterior_interval(model)

# Visualize posterior distributions
mcmc_areas(model)

# Predictive performance
# Compare observed vs. predicted
predicted_permits <- posterior_predict(model)
```

```{r}
# model summary

```
